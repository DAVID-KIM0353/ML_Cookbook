{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 순서가 없는 범주형 특성 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([['Texas'],\n",
    "                   ['California'],\n",
    "                   ['Texas'],\n",
    "                   ['Delaware'],\n",
    "                   ['Texas']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코더\n",
    "one_hot = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 원-핫 인코딩 한다.\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 클래스 확인하기\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원-핫 인코딩 되돌리기\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(feature[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 특성 만들기\n",
    "multiclass_feature = [('Texas', 'Florida'),\n",
    "                      ('California', 'Alabama'),\n",
    "                      ('Texas', 'Florida'),\n",
    "                      ('Delware', 'Florida'),\n",
    "                      ('Texas', 'Alabama')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 원-핫 인코더\n",
    "one_hot_multiclass = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 클래스 특성을 원-핫 인코더 하기\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 확인\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주가 순서에 영향이 있는지 없는지 먼저 판단한다!\\\n",
    "예를 들면 Texas:1 는 Alabama:2 보다 작지 않다.\\\n",
    "따라서 특성을 먼저 잘 파악한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelBinerizer: 문자열 타깃 데이터를 원-핫 인코딩으로 변환할 때 사용\\\n",
    "LabelEncoder: 문자열 타깃 데이터를 정수 레이블로 변환할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([['Texas', 1],\n",
    "                    ['California', 1],\n",
    "                    ['Texas', 3],\n",
    "                    ['Delaware', 1],\n",
    "                    ['Texas', 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder 클래스는 기본적으로 희소 배열을 반환한다. sparse = False로 지정하면 밀집 배열을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "one_hot_encoder.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "California, Delaware, Texas가 처음 세 개의 열에 원-핫 인코딩되었고, 1과 3이 나머지 두 개의 열에 원-핫 인코딩되었다.\\\n",
    "이 예에서처럼 정수도 문자열처럼 취급하여 변환된다.\\\n",
    "categories_ 속성으로 클래스를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['California', 'Delaware', 'Texas'], dtype='<U10'),\n",
       " array(['1', '3'], dtype='<U10')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder는 입력 특성 배열을 모두 범주형으로 인식하여 반환한다.\\\n",
    "특정 열에만 적용하려면 이전 장에서 설명한 ColumnTransformer와 함께 사용하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 순서가 있는 범주형 특성 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({'Score': ['Low', 'Low', 'Medium', 'Medium', 'High']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매핑 딕셔너리\n",
    "scale_mapper = {'Low': 1,\n",
    "               'Medium': 2,\n",
    "               'High': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Score'].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서가 포함된 경우\\\n",
    "예시) 매우 그렇다, 그렇다, 보통이다, 그렇지 않다, 전혀 그렇지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서가 있을 땐 수치값으로 변환하는게 일반적이다.\\\n",
    "어떤 수치값을 선택하는지는 클래스에 내재된 순서 정보에 기반한다는 사실을 유념해야한다.\\\n",
    "해결에선 high는 글자 그대로 low보다 세 배 더 크다. 경우에 따라 이런 설정이 잘 맞을 수 있지만 클래스 사이 간격이 동일하지 않는다면 문제가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({'Score': ['Low',\n",
    "                                    'Low',\n",
    "                                    'Medium',\n",
    "                                    'Medium',\n",
    "                                    'High',\n",
    "                                    'Barely More Than Medium']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper = {'Low': 1,\n",
    "                'Medium': 2,\n",
    "                'Barely More Than Medium' : 3,\n",
    "                'High': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score\n",
       "0      1\n",
       "1      1\n",
       "2      2\n",
       "3      2\n",
       "4      4\n",
       "5      3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보다 정확하게 하기 위해서 mapping할 때 좀 정밀한 수치로 만들어주기\n",
    "\n",
    "scale_mapper = {'Low': 1,\n",
    "                'Medium': 2,\n",
    "                'Barely More Than Medium': 2.1,\n",
    "                'High': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score\n",
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    3.0\n",
       "5    2.1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder을 이용하여 범주형 인코딩 해보기\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Low', '10'],\n",
       "       ['High', '50'],\n",
       "       ['Medium', '3']], dtype='<U6')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([['Low', 10],\n",
    "                     ['High', 50],\n",
    "                     ['Medium', 3]])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 2.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['High', 'Low', 'Medium'], dtype='<U6'),\n",
       " array(['10', '3', '50'], dtype='<U6')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 확인\n",
    "\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 특성 딕셔너리를 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [{'Red': 2, 'Blue': 4},\n",
    "             {'Red': 4, 'Blue': 3},\n",
    "             {'Red': 1, 'Yellow': 2},\n",
    "             {'Red': 2, 'Yellow': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicvectorizer = DictVectorizer(sparse = False)\n",
    "features = dicvectorizer.fit_transform(data_dict)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DicVectorizer는 0이 아닌 값의 원소만 저장하는 희소 행렬을 반환한다.\\\n",
    "Dicvectorizer를 sparse = False 로 지정하면 밀집 벡터를 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 이름 얻기\n",
    "feature_names = dicvectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0\n",
       "3   0.0  2.0     2.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스 사용\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(features, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 알고리즘은 행렬 형태의 데이터를 기대한다.\\\n",
    "DictVectorizer 는 자연어 처리 분야에서 자주 사용한다.\\\n",
    "DictVectorizer를 사용하면 각 문서에 등장한 단어 횟수를 특성으로 하는 특성 행렬을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네 개의 문서에 대한 단어 카운트 딕셔너리 만들기.\n",
    "\n",
    "doc_1_word_count = {'Red': 2, 'Blue': 4}\n",
    "doc_2_word_count = {'Red': 4, 'Blue': 3}\n",
    "doc_3_word_count = {'Red': 1, 'Yellow': 2}\n",
    "doc_4_word_count = {'Red': 2, 'Yellow': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 만들기\n",
    "doc_word_counts = [doc_1_word_count, doc_2_word_count, doc_3_word_count, doc_4_word_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Red': 2, 'Blue': 4},\n",
       " {'Red': 4, 'Blue': 3},\n",
       " {'Red': 1, 'Yellow': 2},\n",
       " {'Red': 2, 'Yellow': 2}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicvectorizer.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예제는 고유한 단어가 세 개(Red, Yellow, Blue) 뿐이므로 행렬에 세 개의 특성만 있다.\\\n",
    "문서가 대학 도서관에 있는 어떤 책이라면 아주 큰 특성 행렬이 만들어진다(sparse 매개변수를 True로 설정해야한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 누락된 클래스 값 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 knn 분류기를 사용한다.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 특성을 가진 행렬 만들기\n",
    "\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "              [1, 1.18, 1.33],\n",
    "              [0, 1.22, 1.27],\n",
    "              [1, -0.21, -1.19]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 특성에 누락된 값이 있는 특성 행렬을 만든다.\n",
    "\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.13],\n",
    "                       [np.nan, -0.67, -0.22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn 학습기를 훈련한다.\n",
    "\n",
    "clf = KNeighborsClassifier(3, weights = 'distance')\n",
    "trained_model = clf.fit(X[:, 1:], X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값의 클래스를 예측한다.\n",
    "\n",
    "imputed_values = trained_model.predict(X_with_nan[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측된 클래스와 원본 특성을 열로 합친다.\n",
    "# reshape(-1, 1): 행은 많고 열은 한개로\n",
    "# hstack: 열방향으로 합치기\n",
    "\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1, 1), X_with_nan[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.13],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 특성 행렬을 연결한다.\n",
    "# vstack: 행방향으로 합치기\n",
    "\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "누락된 값을 특성에서 가장 자주 등장하는 값으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 행렬 합치기\n",
    "\n",
    "X_complete = np.vstack((X_with_nan, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.13],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 불균형한 클래스 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 불균형할 때 더 많은 데이터를 모아라. 이것이 안되면 모델 평가 지표를 바꿔라.\\\n",
    "잘 동작하지 않으면 (가능하다면) 모델에 내장된 클래스 가중치 매개변수를 사용하거나 다운샘플링이나 업샘플링을 고려해보아라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 40개 샘플 삭제하기\n",
    "features = features[40:, :]\n",
    "target = target[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 0을 음성 클래스로 하는 이진 타깃 벡터를 만든다.\n",
    "# target == 0 이면 참은 0, 거짓은 1로 바꿔라\n",
    "\n",
    "target = np.where((target == 0), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불균형한 타깃 벡터 확인\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에 잇는 많은 알고리즘은 훈련할 때 불균형한 영향을 줄일  수 있도록 클래스에 가중치를 부여할 수 있는 매개변수를 제공한다.\\\n",
    "가장 인기 높은 분류 알고리즘: RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치를 만든다.\n",
    "\n",
    "weights = {0: .9, 1: 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치를 부여한 랜덤 포레스트 분류기를 만든다.\n",
    "RandomForestClassifier(class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanced로 지정하여 클래스 빈도에 반비례하게 자동으로 가중치를 만들 수 있다.\n",
    "# 균형잡힌 클래스 가중치로 랜덤 포레스트 모델을 훈련한다.\n",
    "\n",
    "RandomForestClassifier(class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다수 클래스의 샘플을 줄이거나(다운샘플링) 소수 클래스의 샘플을 늘릴 수도 있다(업샘플링)\\\n",
    "- 다운샘플링: 다수 클래스에서 중복을 허용하지 않고 랜덤하게 샘플을 선택하여 소수클래스와 같은 크기의 샘플 부분집합을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스의 샘플 인덱스를 추출한다.\n",
    "\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,\n",
       "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
       "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
       "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
       "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
       "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스의 샘플 개수\n",
    "\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 0의 샘플만큼 클래스 1에서 중복을 허용하지 않고 랜덤하게 샘플을 뽑는다.\n",
    "\n",
    "i_class1_downsampled = np.random.choice(i_class1, size = n_class0,\n",
    "                                       replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 타깃 벡터와 다운샘플링된 클래스 1의 타깃 벡터를 합친다.\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 특성 행렬과 다운샘플링된 클래스 1의 특성 행렬을 합친다.\n",
    "\n",
    "np.vstack((features[i_class0, :], features[i_class1_downsampled, :]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 소수 클래스를 업샘플링하는 방법\\\n",
    "업샘플링에서는 다수 클래스의 샘플만큼 소수 클래스에서 중복을 허용하여 랜덤하게 샘플을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 1의 샘플 개수만큼 클래스 0에서 중복을 허용하여 랜덤하게 샘플을 선택한다.\n",
    "\n",
    "i_class0_upsampled = np.random.choice(i_class0, size = n_class1, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 8, 6, 9, 1, 9, 9, 5, 4, 9, 8, 2, 0, 0, 7, 2, 5, 5, 6, 0, 8,\n",
       "       3, 3, 5, 6, 7, 7, 8, 9, 9, 0, 6, 8, 7, 4, 1, 7, 5, 6, 2, 2, 8, 0,\n",
       "       1, 9, 6, 0, 5, 0, 2, 7, 3, 8, 8, 3, 1, 1, 8, 6, 0, 7, 3, 8, 0, 4,\n",
       "       9, 7, 5, 8, 0, 7, 1, 6, 6, 7, 9, 2, 4, 7, 4, 8, 6, 6, 9, 4, 9, 2,\n",
       "       5, 7, 4, 9, 0, 3, 0, 0, 8, 7, 9, 4], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class0_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 업샘플링된 타깃 벡터와 클래스 1의 타깃 벡터를 합친ㅇ다.\n",
    "\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.8, 1.6, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 0의 업샘플링된 특성 행렬과 클래스 1의 특성 행렬을 합친다.\n",
    "\n",
    "np.vstack((features[i_class0_upsampled, :], features[i_class1, :]))[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
