{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 특성 스케일 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([[-500.5],\n",
    "                   [-100.1],\n",
    "                   [0],\n",
    "                   [100.1],\n",
    "                   [900.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 객체 만들기\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성의 스케일을 변환하기\n",
    "scaled_feature = minmax_scale.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 출력하기\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일 조정은 머신러닝에서 흔한 전처리 작업이다.\\\n",
    "최솟값과 최댓값을 사용하여 일정 범위 안으로 값을 조정한다.\\\n",
    "xi' = xi-min(x) / max(x)-min(x)\\\n",
    "\\\n",
    "xi는 특성 x의 개별 원소이고, xi는 특성 백터이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######\n",
    "훈련 세트와 테스트 세트의 스케일을 따로 조정하면 안된다. 예를 들면 훈련 세트의 스케일을 조정하고자 구한 최솟값과 최댓값을 사용하여 테스트 세트를 반환해야 한다. 아래는 간단한 예 이다.\\\\\n",
    "\n",
    "\\\n",
    "다음 샘플 중 처음 세개를 훈련 세트, 나머지 두 개를 테스트 세트라고 가정해본다.\\\n",
    "먼저 두 세트를 독립적으로 각각 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트를 변환한다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 세트를 변환한다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트와 테스트 세트를 각각 변환하면 서로 다른 비율로 데이터를 변환한다. 이러면 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트로 변환기를 학습한다.\n",
    "scaler = preprocessing.MinMaxScaler().fit(feature[:3])\n",
    "scaler.transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2],\n",
       "       [2.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트에서 학습한 변환기로 테스트 세트를 변환한다.\n",
    "scaler.transform(feature[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트를 학습한 변환기 객체를 사용하여 원본 데이터셋과 동일한 비률로 테스트를 변환했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 특성을 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[-1000.1],\n",
    "             [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체 만들기.\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 변환한다.\n",
    "standardized = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 출력한다.\n",
    "standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1에서 설명한 최소-최대 스케일링과 함께 특성을 표준 정규분포로 근사하는 스케일링 방식이 자주 쓰인다.\\\n",
    "이 방식은 표준화를 사용하여 데이터의 평균이 0이고 표준편차가 1이 되도록 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식은 머신러닝에서 상당히 많이 쓰인다. 하지만 학습 알고리즘에 의존적이다.\\\n",
    "예를 들어 주성분 분석은 표준화가 잘 맞지만 신경망에는 최소-최대 스케일링을 종종 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 0\n",
      "표준편차: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 평균과 표준편차를 출력한다,\n",
    "print('평균:', round(standardized.mean()))\n",
    "print('표준편차:', standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치가 많을 경우엔 중간값과 사분위 범위를 사용하여 특성의 스케일을 조정하는 것이 좋다. RobusScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체를 만든다.\n",
    "robust_scaler = preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 변환한다.\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobusScaler는 데이터에서 중간값을 빼고 IQR로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interquatile_range = x[3] - x[1]\n",
    "\n",
    "(x - np.median(x)) / interquatile_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantileTransformer는 훈련 데이터를 1,000개의 분위로 나누어 0~1 사이에 고르게 분포시킴으로써 이상치로 인한 영향을 줄인다.\\\n",
    "예를 들어 해결에 나온 특성 x는 다섯 개의 샘플을 가지고 있으므로 0%, 25%, 50%, 75%, 100%의 위치에 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2367: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.QuantileTransformer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
