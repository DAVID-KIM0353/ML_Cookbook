{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 특성 스케일 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([[-500.5],\n",
    "                   [-100.1],\n",
    "                   [0],\n",
    "                   [100.1],\n",
    "                   [900.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 객체 만들기\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성의 스케일을 변환하기\n",
    "scaled_feature = minmax_scale.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 출력하기\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일 조정은 머신러닝에서 흔한 전처리 작업이다.\\\n",
    "최솟값과 최댓값을 사용하여 일정 범위 안으로 값을 조정한다.\\\n",
    "xi' = xi-min(x) / max(x)-min(x)\\\n",
    "\\\n",
    "xi는 특성 x의 개별 원소이고, xi는 특성 백터이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######\n",
    "훈련 세트와 테스트 세트의 스케일을 따로 조정하면 안된다. 예를 들면 훈련 세트의 스케일을 조정하고자 구한 최솟값과 최댓값을 사용하여 테스트 세트를 반환해야 한다. 아래는 간단한 예 이다.\\\\\n",
    "\n",
    "\\\n",
    "다음 샘플 중 처음 세개를 훈련 세트, 나머지 두 개를 테스트 세트라고 가정해본다.\\\n",
    "먼저 두 세트를 독립적으로 각각 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트를 변환한다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 세트를 변환한다.\n",
    "preprocessing.MinMaxScaler().fit_transform(feature[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트와 테스트 세트를 각각 변환하면 서로 다른 비율로 데이터를 변환한다. 이러면 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.8],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트로 변환기를 학습한다.\n",
    "scaler = preprocessing.MinMaxScaler().fit(feature[:3])\n",
    "scaler.transform(feature[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2],\n",
       "       [2.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 세트에서 학습한 변환기로 테스트 세트를 변환한다.\n",
    "scaler.transform(feature[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트를 학습한 변환기 객체를 사용하여 원본 데이터셋과 동일한 비률로 테스트를 변환했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 특성을 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[-1000.1],\n",
    "             [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체 만들기.\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 변환한다.\n",
    "standardized = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 출력한다.\n",
    "standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1에서 설명한 최소-최대 스케일링과 함께 특성을 표준 정규분포로 근사하는 스케일링 방식이 자주 쓰인다.\\\n",
    "이 방식은 표준화를 사용하여 데이터의 평균이 0이고 표준편차가 1이 되도록 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식은 머신러닝에서 상당히 많이 쓰인다. 하지만 학습 알고리즘에 의존적이다.\\\n",
    "예를 들어 주성분 분석은 표준화가 잘 맞지만 신경망에는 최소-최대 스케일링을 종종 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 0\n",
      "표준편차: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 평균과 표준편차를 출력한다,\n",
    "print('평균:', round(standardized.mean()))\n",
    "print('표준편차:', standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상치가 많을 경우엔 중간값과 사분위 범위를 사용하여 특성의 스케일을 조정하는 것이 좋다. RobusScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체를 만든다.\n",
    "robust_scaler = preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성을 변환한다.\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobusScaler는 데이터에서 중간값을 빼고 IQR로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interquatile_range = x[3] - x[1]\n",
    "\n",
    "(x - np.median(x)) / interquatile_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantileTransformer는 훈련 데이터를 1,000개의 분위로 나누어 0~1 사이에 고르게 분포시킴으로써 이상치로 인한 영향을 줄인다.\\\n",
    "예를 들어 해결에 나온 특성 x는 다섯 개의 샘플을 가지고 있으므로 0%, 25%, 50%, 75%, 100%의 위치에 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2367: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.QuantileTransformer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 행렬 만들기\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.3],\n",
    "                    [10.9, 3.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환기 객체 만들기\n",
    "normalizer = Normalizer(norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.0474683 , 0.99887275],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 행렬을 변환한다.\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer는 단위 노름(길이의 합이 1이다)이 되도록 개별 샘플의 값을 변환한다.\\\n",
    "이런 종류의 스케일링은 (예를 들어 각 단어나 n개의 단어 그룹이 특성인 텍스트 분류와 같이) 유사한 특성이 많을 때 종종 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 행렬을 변환한다.\n",
    "features_l2_norm = Normalizer(norm = 'l2').transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.0474683 , 0.99887275],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 행렬을 출력한다.\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨해튼 노름(l1)을 지정할 수도 있다.\n",
    "# 특성 행렬을 변환한다.\n",
    "features_l1_norm = Normalizer(norm = 'l1').transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04536599, 0.95463401],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 행렬을 출력한다.\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2 노름은 뉴욕의 두 지점 사이를 잇는 직선 거리로 볼 수 있다.\\\n",
    "l1 노름은 사람이 도로를 따라 걷는 것과 같다.\\\n",
    "이를 '맨해튼 노름', '택시 노름'으로 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플값의 합:  1.0\n"
     ]
    }
   ],
   "source": [
    "# norm = 'l1'은 각 샘플 특성값의 합을 1로 만든다.\n",
    "# 합을 출력한다.\n",
    "\n",
    "print('첫 번째 샘플값의 합: ',\n",
    "     features_l1_norm[0, 1] + features_l1_norm[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer는 행 단위로 변환되므로 fit 메서드는 아무런 작업을 수행하지 않는다.\\\n",
    "이런 이유로 해결의 코드처럼 바로 transform 메서드를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04536599, 0.95463401],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 노름을 사용한 변환.\n",
    "# 각 행(axis = 1)을 합한 결과가 2차원 배열로 유지되도록\n",
    "# keepdims를 True로 설정한다.\n",
    "\n",
    "features / np.sum(np.abs(features), axis = 1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.0474683 , 0.99887275],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 노름을 사용한 변환\n",
    "features / np.sqrt(np.sum(np.square(features), axis = 1, keepdims = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer의 norm 매개변수에 지정할 수 있는 다른 한 가지 옵션은 'max'이다. 이 옵션은 단순히 각 행의 최댓값으로 행의 값을 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        ],\n",
       "       [0.32352941, 1.        ],\n",
       "       [0.07425743, 1.        ],\n",
       "       [0.04752187, 1.        ],\n",
       "       [1.        , 0.30275229]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 행에서 최댓값으로 나눈다.\n",
    "Normalizer(norm = 'max').transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 다항 특성과 교차항 특성 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial_interaction = PolynomialFeatures(degree = 2, include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다항 특성 만들기.\n",
    "Polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "degree 매개변수가 다항식의 최대 차수를 결정한다.\\\n",
    "예를 들어 degree = 2는 2제곱까지 새로운 특성을 만든다.\\\n",
    "x1,x2,x1(2),x2(2)\\\n",
    "\\\n",
    "degree=3은 3제곱까지 새로운 특성을 만든다.\\\n",
    "x1,x2,x1(2),x2(2),x1(3),x2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 PolynomialFeatrues는 교차항을 포함한다.\\\n",
    "interaction_only를 True로 지정하면 교차항 특성만 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction = PolynomialFeatures(degree = 2,\n",
    "                                interaction_only = True, include_bias = False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성과 타깃 사이에 비선형 관계가 있다는 가정을 추가할 때 다항 특성을 종종 만든다.\\\n",
    "개별 특성을 곱한 교차항을 특성에 추가하여 이런 관계를 인코딩할 수 있다.(예시: 커피당도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 6., 9.],\n",
       "       [1., 2., 3., 4., 6., 9.],\n",
       "       [1., 2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상수항 1을 추가한다.\n",
    "polynomial_bias = PolynomialFeatures(degree = 2,\n",
    "                                    include_bias = True).fit(features)\n",
    "polynomial_bias.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_feature_names 메서드는 특성 변환 식을 이름으로 반환한다.\n",
    "polynomial_bias.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 특성 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ten(x):\n",
    "    return x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_transformer = FunctionTransformer(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판다스의 apply 메서드를 사용하여 동일한 변환을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
